{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image as pil_image\n",
    "from IPython.display import Image as Image\n",
    "from matplotlib.pyplot import imshow, imsave\n",
    "\n",
    "np.random.seed(123)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "import itertools\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "Using TensorFlow backend.\n",
    "main_df = pd.read_csv('HAM10000_metadata.csv')\n",
    "main_df.head()\n",
    "lesion_id\timage_id\tdx\tdx_type\tage\tsex\tlocalization\n",
    "0\tHAM_0000118\tISIC_0027419\tbkl\thisto\t80.0\tmale\tscalp\n",
    "1\tHAM_0000118\tISIC_0025030\tbkl\thisto\t80.0\tmale\tscalp\n",
    "2\tHAM_0002730\tISIC_0026769\tbkl\thisto\t80.0\tmale\tscalp\n",
    "3\tHAM_0002730\tISIC_0025661\tbkl\thisto\t80.0\tmale\tscalp\n",
    "4\tHAM_0001466\tISIC_0031633\tbkl\thisto\t75.0\tmale\tear\n",
    "sns.countplot(main_df['dx'])\n",
    "c:\\users\\nprav\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
    "  warnings.warn(\n",
    "<AxesSubplot:xlabel='dx', ylabel='count'>\n",
    "\n",
    "main_df['dx'].value_counts()\n",
    "nv       6705\n",
    "mel      1113\n",
    "bkl      1099\n",
    "bcc       514\n",
    "akiec     327\n",
    "vasc      142\n",
    "df        115\n",
    "Name: dx, dtype: int64\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(main_df['localization'])\n",
    "plt.xticks(rotation=90)\n",
    "c:\\users\\nprav\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
    "  warnings.warn(\n",
    "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
    " [Text(0, 0, 'scalp'),\n",
    "  Text(1, 0, 'ear'),\n",
    "  Text(2, 0, 'face'),\n",
    "  Text(3, 0, 'back'),\n",
    "  Text(4, 0, 'trunk'),\n",
    "  Text(5, 0, 'chest'),\n",
    "  Text(6, 0, 'upper extremity'),\n",
    "  Text(7, 0, 'abdomen'),\n",
    "  Text(8, 0, 'unknown'),\n",
    "  Text(9, 0, 'lower extremity'),\n",
    "  Text(10, 0, 'genital'),\n",
    "  Text(11, 0, 'neck'),\n",
    "  Text(12, 0, 'hand'),\n",
    "  Text(13, 0, 'foot'),\n",
    "  Text(14, 0, 'acral')])\n",
    "\n",
    "sns.countplot(main_df['dx_type'])\n",
    "c:\\users\\nprav\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
    "  warnings.warn(\n",
    "<AxesSubplot:xlabel='dx_type', ylabel='count'>\n",
    "\n",
    "main_df['dx_type'].value_counts()\n",
    "histo        5340\n",
    "follow_up    3704\n",
    "consensus     902\n",
    "confocal       69\n",
    "Name: dx_type, dtype: int64\n",
    "main_df.isna().sum().sort_values(ascending=False)\n",
    "age             57\n",
    "localization     0\n",
    "sex              0\n",
    "dx_type          0\n",
    "dx               0\n",
    "image_id         0\n",
    "lesion_id        0\n",
    "dtype: int64\n",
    "print(main_df['age'].mean())\n",
    "print(main_df['age'].median())\n",
    "main_df['age'].fillna(main_df['age'].mean(),inplace=True)\n",
    "51.863828077927295\n",
    "50.0\n",
    "sns.kdeplot(main_df['age'],shade=True)\n",
    "<AxesSubplot:xlabel='age', ylabel='Density'>\n",
    "\n",
    "main_df['sex'].value_counts()\n",
    "male       5406\n",
    "female     4552\n",
    "unknown      57\n",
    "Name: sex, dtype: int64\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "lesion_classes_dict = {\n",
    "    0:'nv',\n",
    "    1:'mel',\n",
    "    2:'bkl',\n",
    "    3:'bcc',\n",
    "    4:'akiec',\n",
    "    5:'vasc',\n",
    "    6:'df'\n",
    "}\n",
    "\n",
    "main_df['cell_type'] = main_df['dx'].map(lesion_type_dict)\n",
    "main_df['cell_type_idx'] = pd.Categorical(main_df['cell_type']).codes\n",
    "sns.catplot(x=\"sex\", y=\"cell_type_idx\",\n",
    "                    hue=\"sex\",\n",
    "                    data=main_df,\n",
    "                    kind=\"violin\")\n",
    "<seaborn.axisgrid.FacetGrid at 0x1ae5a41bf70>\n",
    "\n",
    "import os\n",
    "#pil_image = os.path.join('images')\n",
    "image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "              for x in glob(os.path.join('', '*', '*.jpg'))}\n",
    "main_df['path'] = main_df['image_id'].map(image_path.get)\n",
    "main_df.head()\n",
    "lesion_id\timage_id\tdx\tdx_type\tage\tsex\tlocalization\tcell_type\tcell_type_idx\tpath\n",
    "0\tHAM_0000118\tISIC_0027419\tbkl\thisto\t80.0\tmale\tscalp\tBenign keratosis-like lesions\t2\tHAM10000_images_part_1\\ISIC_0027419.jpg\n",
    "1\tHAM_0000118\tISIC_0025030\tbkl\thisto\t80.0\tmale\tscalp\tBenign keratosis-like lesions\t2\tHAM10000_images_part_1\\ISIC_0025030.jpg\n",
    "2\tHAM_0002730\tISIC_0026769\tbkl\thisto\t80.0\tmale\tscalp\tBenign keratosis-like lesions\t2\tHAM10000_images_part_1\\ISIC_0026769.jpg\n",
    "3\tHAM_0002730\tISIC_0025661\tbkl\thisto\t80.0\tmale\tscalp\tBenign keratosis-like lesions\t2\tHAM10000_images_part_1\\ISIC_0025661.jpg\n",
    "4\tHAM_0001466\tISIC_0031633\tbkl\thisto\t75.0\tmale\tear\tBenign keratosis-like lesions\t2\tHAM10000_images_part_2\\ISIC_0031633.jpg\n",
    "image_example = np.asarray(pil_image.open(main_df['path'][0]))\n",
    "image_example.shape\n",
    "(450, 600, 3)\n",
    "plt.imshow(image_example)\n",
    "<matplotlib.image.AxesImage at 0x1ae5b8e42b0>\n",
    "\n",
    "main_df['image'] = main_df['path'].map(lambda x: np.asarray(pil_image.open(x).resize((120,90))))\n",
    "main_df.head()\n",
    "lesion_id\timage_id\tdx\tdx_type\tage\tsex\tlocalization\tcell_type\tcell_type_idx\tpath\timage\n",
    "0\tHAM_0000118\tISIC_0027419\tbkl\thisto\t80.0\tmale\tscalp\tBenign keratosis-like lesions\t2\tHAM10000_images_part_1\\ISIC_0027419.jpg\t[[[190, 152, 194], [192, 155, 197], [191, 154,...\n",
    "1\tHAM_0000118\tISIC_0025030\tbkl\thisto\t80.0\tmale\tscalp\tBenign keratosis-like lesions\t2\tHAM10000_images_part_1\\ISIC_0025030.jpg\t[[[24, 13, 22], [24, 14, 23], [24, 14, 26], [2...\n",
    "2\tHAM_0002730\tISIC_0026769\tbkl\thisto\t80.0\tmale\tscalp\tBenign keratosis-like lesions\t2\tHAM10000_images_part_1\\ISIC_0026769.jpg\t[[[185, 126, 135], [189, 133, 145], [192, 135,...\n",
    "3\tHAM_0002730\tISIC_0025661\tbkl\thisto\t80.0\tmale\tscalp\tBenign keratosis-like lesions\t2\tHAM10000_images_part_1\\ISIC_0025661.jpg\t[[[24, 11, 17], [25, 11, 20], [31, 16, 27], [4...\n",
    "4\tHAM_0001466\tISIC_0031633\tbkl\thisto\t75.0\tmale\tear\tBenign keratosis-like lesions\t2\tHAM10000_images_part_2\\ISIC_0031633.jpg\t[[[131, 89, 111], [143, 98, 121], [153, 108, 1...\n",
    "plt.imshow(main_df['image'][0])\n",
    "<matplotlib.image.AxesImage at 0x1ae5da86af0>\n",
    "\n",
    "main_df['image'][0].shape\n",
    "(90, 120, 3)\n",
    "fig,axes = plt.subplots(7,5,figsize=(20,21))\n",
    "for nth_axis,(cell_type_name,cell_type_row) in zip(axes,main_df.sort_values(['cell_type']).groupby('cell_type')):\n",
    "    nth_axis[0].set_title(cell_type_name)\n",
    "    for column_axis,(_,column_row) in zip(nth_axis,cell_type_row.sample(5).iterrows()):\n",
    "        column_axis.imshow(column_row['image'])  \n",
    "        column_axis.axis('off')\n",
    "\n",
    "features = main_df.drop(['cell_type_idx'],axis=1)\n",
    "\n",
    "target = main_df['cell_type_idx']\n",
    "\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(features,target,test_size=0.01)\n",
    "x_train = np.asarray(X_TRAIN['image'].tolist())\n",
    "x_test = np.asarray(X_TEST['image'].tolist())\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "(9914, 90, 120, 3)\n",
    "(101, 90, 120, 3)\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train-x_train_mean) / x_train_std\n",
    "x_test = (x_test-x_test_mean) / x_test_std\n",
    "print(Y_TRAIN.shape)\n",
    "print(Y_TEST.shape)\n",
    "(9914,)\n",
    "(101,)\n",
    "y_train = to_categorical(Y_TRAIN,num_classes=7)\n",
    "y_test = to_categorical(Y_TEST,num_classes=7)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "(9914, 7)\n",
    "(101, 7)\n",
    "X_train,X_val, Y_train,Y_val = train_test_split(x_train,y_train,test_size=0.15)\n",
    "X_train  = X_train.reshape(X_train.shape[0],90,120,3)\n",
    "x_test  = x_test.reshape(x_test.shape[0],90,120,3)\n",
    "X_val  = X_val.reshape(X_val.shape[0],90,120,3)\n",
    "print(X_train.shape)\n",
    "print(x_test.shape)\n",
    "print(X_val.shape)\n",
    "(8426, 90, 120, 3)\n",
    "(101, 90, 120, 3)\n",
    "(1488, 90, 120, 3)\n",
    "input_shape = (90, 120, 3)\n",
    "num_classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "model.add(Conv2D(32,kernel_size=(3, 3),activation='relu',padding = 'Same'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding ='Same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding ='Same'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d (Conv2D)              (None, 90, 120, 32)       896       \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 90, 120, 32)       9248      \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 45, 60, 32)        0         \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 45, 60, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 45, 60, 64)        18496     \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 45, 60, 64)        36928     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 22, 30, 64)        0         \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 22, 30, 64)        0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 42240)             0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 128)               5406848   \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 7)                 903       \n",
    "=================================================================\n",
    "Total params: 5,473,319\n",
    "Trainable params: 5,473,319\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=4, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.0001, \n",
    "                                            min_lr=0.000001)\n",
    "# With data augmentation to prevent overfitting \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1 # Randomly zoom image \n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])\n",
    "WARNING:tensorflow:From <ipython-input-38-7ee955826130>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please use Model.fit, which supports generators.\n",
    "Epoch 1/30\n",
    "526/526 [==============================] - 345s 655ms/step - loss: 0.9943 - accuracy: 0.6663 - val_loss: 0.8619 - val_accuracy: 0.6969\n",
    "Epoch 2/30\n",
    "526/526 [==============================] - 330s 628ms/step - loss: 0.8888 - accuracy: 0.6803 - val_loss: 0.7749 - val_accuracy: 0.7097\n",
    "Epoch 3/30\n",
    "526/526 [==============================] - 332s 630ms/step - loss: 0.8456 - accuracy: 0.6957 - val_loss: 0.7426 - val_accuracy: 0.7184\n",
    "Epoch 4/30\n",
    "526/526 [==============================] - 330s 627ms/step - loss: 0.8140 - accuracy: 0.7050 - val_loss: 0.7511 - val_accuracy: 0.7332\n",
    "Epoch 5/30\n",
    "526/526 [==============================] - 337s 642ms/step - loss: 0.7912 - accuracy: 0.7153 - val_loss: 0.7068 - val_accuracy: 0.7305\n",
    "Epoch 6/30\n",
    "526/526 [==============================] - 342s 650ms/step - loss: 0.7607 - accuracy: 0.7228 - val_loss: 0.6913 - val_accuracy: 0.7339\n",
    "Epoch 7/30\n",
    "526/526 [==============================] - 334s 634ms/step - loss: 0.7431 - accuracy: 0.7314 - val_loss: 0.7172 - val_accuracy: 0.7298\n",
    "Epoch 8/30\n",
    "526/526 [==============================] - 340s 646ms/step - loss: 0.7217 - accuracy: 0.7360 - val_loss: 0.6968 - val_accuracy: 0.7345\n",
    "Epoch 9/30\n",
    "526/526 [==============================] - 283s 538ms/step - loss: 0.7197 - accuracy: 0.7403 - val_loss: 0.6763 - val_accuracy: 0.7379\n",
    "Epoch 10/30\n",
    "526/526 [==============================] - 282s 536ms/step - loss: 0.6909 - accuracy: 0.7466 - val_loss: 0.6772 - val_accuracy: 0.7433\n",
    "Epoch 11/30\n",
    "526/526 [==============================] - 282s 537ms/step - loss: 0.6783 - accuracy: 0.7528 - val_loss: 0.6662 - val_accuracy: 0.7628\n",
    "Epoch 12/30\n",
    "526/526 [==============================] - 282s 537ms/step - loss: 0.6557 - accuracy: 0.7591 - val_loss: 0.6507 - val_accuracy: 0.7554\n",
    "Epoch 13/30\n",
    "526/526 [==============================] - 282s 536ms/step - loss: 0.6410 - accuracy: 0.7643 - val_loss: 0.6910 - val_accuracy: 0.7534\n",
    "Epoch 14/30\n",
    "526/526 [==============================] - 282s 536ms/step - loss: 0.6277 - accuracy: 0.7650 - val_loss: 0.9076 - val_accuracy: 0.7110\n",
    "Epoch 15/30\n",
    "526/526 [==============================] - 288s 547ms/step - loss: 0.6333 - accuracy: 0.7687 - val_loss: 0.7089 - val_accuracy: 0.7487\n",
    "Epoch 16/30\n",
    "526/526 [==============================] - 312s 593ms/step - loss: 0.6154 - accuracy: 0.7773 - val_loss: 0.6442 - val_accuracy: 0.7567\n",
    "Epoch 17/30\n",
    "526/526 [==============================] - 282s 537ms/step - loss: 0.6047 - accuracy: 0.7776 - val_loss: 0.7004 - val_accuracy: 0.7406\n",
    "Epoch 18/30\n",
    "526/526 [==============================] - 284s 539ms/step - loss: 0.5959 - accuracy: 0.7798 - val_loss: 0.6662 - val_accuracy: 0.7460\n",
    "Epoch 19/30\n",
    "526/526 [==============================] - 283s 537ms/step - loss: 0.5779 - accuracy: 0.7839 - val_loss: 0.6840 - val_accuracy: 0.7621\n",
    "Epoch 20/30\n",
    "526/526 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.7902\n",
    "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
    "526/526 [==============================] - 283s 539ms/step - loss: 0.5751 - accuracy: 0.7902 - val_loss: 0.6660 - val_accuracy: 0.7493\n",
    "Epoch 21/30\n",
    "526/526 [==============================] - 283s 538ms/step - loss: 0.5600 - accuracy: 0.7913 - val_loss: 0.6635 - val_accuracy: 0.7507\n",
    "Epoch 22/30\n",
    "526/526 [==============================] - 283s 539ms/step - loss: 0.5504 - accuracy: 0.7922 - val_loss: 0.6610 - val_accuracy: 0.7513\n",
    "Epoch 23/30\n",
    "526/526 [==============================] - 283s 538ms/step - loss: 0.5544 - accuracy: 0.7876 - val_loss: 0.6590 - val_accuracy: 0.7513\n",
    "Epoch 24/30\n",
    "526/526 [==============================] - 285s 543ms/step - loss: 0.5486 - accuracy: 0.7923 - val_loss: 0.6571 - val_accuracy: 0.7527\n",
    "Epoch 25/30\n",
    "526/526 [==============================] - 285s 543ms/step - loss: 0.5493 - accuracy: 0.7902 - val_loss: 0.6556 - val_accuracy: 0.7540\n",
    "Epoch 26/30\n",
    "526/526 [==============================] - 318s 605ms/step - loss: 0.5523 - accuracy: 0.7897 - val_loss: 0.6541 - val_accuracy: 0.7540\n",
    "Epoch 27/30\n",
    "526/526 [==============================] - 332s 632ms/step - loss: 0.5388 - accuracy: 0.7960 - val_loss: 0.6532 - val_accuracy: 0.7534\n",
    "Epoch 28/30\n",
    "526/526 [==============================] - 332s 630ms/step - loss: 0.5354 - accuracy: 0.7974 - val_loss: 0.6518 - val_accuracy: 0.7540\n",
    "Epoch 29/30\n",
    " 83/526 [===>..........................] - ETA: 4:26 - loss: 0.5085 - accuracy: 0.8185\n",
    "model.save('models/model_SC.h5')\n",
    "def plot_(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    f, [ax1, ax2] = plt.subplots(1,2, figsize=(15, 5))\n",
    "    ax1.plot(range(len(acc)), acc, label=\"acc\")\n",
    "    ax1.plot(range(len(acc)), val_acc, label=\"val_acc\")\n",
    "    ax1.set_title(\"Training Accuracy vs Validation Accuracy\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(range(len(loss)), loss, label=\"loss\")\n",
    "    ax2.plot(range(len(loss)), val_loss, label=\"val_loss\")\n",
    "    ax2.set_title(\"Training Loss vs Validation Loss\")\n",
    "    ax2.legend()\n",
    "    \n",
    "    \n",
    "plot_(model.history)\n",
    "\n",
    "print(\"MAXIMUM ACCURACY OF SIMPLE SEQUENTIAL NETWORK is : \", round(max(model.history.history['val_accuracy'])*100,4))\n",
    "MAXIMUM ACCURACY OF SIMPLE SEQUENTIAL NETWORK is :  73.4543\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
